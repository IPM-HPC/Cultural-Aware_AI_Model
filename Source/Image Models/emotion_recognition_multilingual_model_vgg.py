# -*- coding: utf-8 -*-
"""Emotion Recognition MultiLingual Model_vgg.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZbKlYpazEAij091eIYGuUIoEjnaa3r3a
"""

from PIL import Image

image_path = "wikiart/Abstract_Expressionism/aaron-siskind_acolman-1-1955.jpg"

image = Image.open(image_path)

image.show()

image

image2 = Image.open('wikiart/Ukiyo_e/hiroshige_a-bridge-across-a-deep-gorge.jpg')

image2

import torch
import torch.nn as nn
import torchvision.models as models
import torchvision.transforms as transforms
from torch.utils.data import Dataset, DataLoader
from sklearn.metrics import f1_score
import pandas as pd
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np

# Configuration
BATCH_SIZE = 64
EPOCHS = 10
LEARNING_RATE = 0.001
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
UNFREEZE_EVERY_N_EPOCHS = 16

# Load your data
df = pd.read_csv('artelingo_release.csv')

# Update image paths
df['image_file'] = df['image_file'].str.replace('YOUR/PATH/TO/WIKIART', 'wikiart')

import os
def preprocess_dataset(df):
    # Iterate through the dataframe and drop rows with non-existing image paths
    indices_to_drop = []
    for idx, row in df.iterrows():
        image_path = row['image_file']
        if not os.path.exists(image_path):
            #print(f"Image not found: {image_path}. Skipping...")
            indices_to_drop.append(idx)

    df = df.drop(indices_to_drop)
    df.reset_index(drop=True, inplace=True)
    return df

paint_emotion_dict = {}
for i in range(0,1101841) :
    if df.iloc[i,-2] not in paint_emotion_dict.keys():
        paint_emotion_dict[df.iloc[i,-2]] = []
    paint_emotion_dict[df.iloc[i,-2]].append(df.iloc[i,1])

paint_emotion_dict

df2 = pd.DataFrame()

paths = []
labels = []
for k,v in paint_emotion_dict.items():
    paths.append(k)
    labels.append(sorted(list(set(v))))

df2['image_file'] = paths
df2['emotions'] = labels

df2.head()

# Preprocess the dataset to remove rows with non-existing image paths
preprocessed_df = preprocess_dataset(df2)

preprocessed_df.head(3)

# Define your transformations
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

NUM_CLASSES = len(df['emotion_label'].unique())

from sklearn.preprocessing import MultiLabelBinarizer
import random

class EmotionDataset(Dataset):
    def __init__(self, df, transform=None, subset_percentage=0.2):
        self.df = df.sample(frac=subset_percentage, random_state=42)  # Randomly sample a subset of data
        self.transform = transform
        self.mlb = MultiLabelBinarizer()
        self.labels = self.mlb.fit_transform(self.df.emotions)

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        image = Image.open(row['image_file']).convert('RGB')
        if self.transform:
            image = self.transform(image)
        label = torch.tensor(self.labels[idx], dtype=torch.float32)
        return image, label

# Create dataset
dataset = EmotionDataset(preprocessed_df, transform)

# Split the dataset
train_size = int(0.8 * len(dataset))
validation_size = len(dataset) - train_size
train_dataset, validation_dataset = torch.utils.data.random_split(dataset, [train_size, validation_size])

# Create dataloader
train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
validation_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False)

# Load pre-trained VGG model
model = models.vgg16(pretrained=True)

# Freeze the model
for param in model.parameters():
    param.requires_grad = True

# Replace the classifier (fully connected) layers
num_ftrs = model.classifier[6].in_features
model.classifier[6] = nn.Sequential(
    nn.Linear(num_ftrs, 768),
    nn.ReLU(),
    nn.BatchNorm1d(768),
    nn.Dropout(0.5),
    nn.Linear(768, 128),
    nn.ReLU(),
    nn.BatchNorm1d(128),
    nn.Dropout(0.5),
    nn.Linear(128, NUM_CLASSES),
    nn.Sigmoid()
)

model = model.to(DEVICE)

criterion = nn.L1Loss()
optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)

import time

def accuracy_score_cal(trues, preds):
    # print(trues.shape)
    total_acc = 0
    for row1, row2 in zip(trues, preds):
        total_acc += accuracy_score(row1, row2, normalize=False)
        # print(f'current acc {total_acc}')
        # print(f'row1 : {row1}\nrow : {row2}')
    return total_acc

from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, hamming_loss
import time
import torch
import torch.nn as nn
import matplotlib.pyplot as plt

history = {'epoch': [], 'train_loss': [], 'train_acc': [], 'train_f1': [], 'train_precision': [], 'train_recall': [], 'train_hamming_loss':[],
               'val_loss': [], 'val_acc': [], 'val_f1': [], 'val_precision': [], 'val_recall': [], 'val_hamming_loss':[]}

def train(model, train_loader, val_loader, criterion, optimizer, device, num_epochs, csv_file, history):
    since = time.time()
    best_val_acc = 0.0
    for epoch in range(num_epochs):

        # Unfreeze all parameters every unfreeze_every_n_epochs epochs
        # if epoch == 11:
        #     for param in model.parameters():
        #         param.requires_grad = True
        # if epoch == 16:
        #     for param in model.parameters():
        #         param.requires_grad = False


        model.train()
        train_loss = 0.0
        train_correct = 0.0
        train_total = 0.0
        train_total_acc = 0.0
        train_predictions = []
        train_targets = []

        start_time = time.time()
        prev_time = start_time

        for batch_idx, (images, labels) in enumerate(train_loader):
            images = images.to(device)
            labels = labels.to(device)

            optimizer.zero_grad()

            outputs = model(images)
            #print(outputs)
            _, predicted = torch.max(outputs.data, 1)
            predicted = (outputs > 0.5).float()
            # predicted = F.one_hot(predicted, num_classes=NUM_CLASSES).float()
            # if(batch_idx % 10 == 0):
            #   print(f'{labels} \n {outputs}')
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            # Convert predicted and labels tensors to NumPy arrays
            predicted_numpy = predicted.cpu().numpy()
            labels_numpy = labels.cpu().numpy()

            train_loss += loss.item() * images.size(0)
            train_correct += accuracy_score_cal(labels_numpy, predicted_numpy)
            train_total += labels.size(0)
            train_total_acc += 64*9
            # print(train_correct)
            # print(train_total)
            train_predictions.extend(predicted.tolist())
            train_targets.extend(labels.tolist())

            # Calculate additional evaluation metrics
            train_hamming_loss = hamming_loss(train_targets, train_predictions)
            train_f1 = f1_score(train_targets, train_predictions, average='micro')
            train_precision = precision_score(train_targets, train_predictions, average='micro')
            train_recall = recall_score(train_targets, train_predictions, average='micro')


            curr_time = time.time()
            if curr_time - prev_time >= 1.0:  # Print every second
                train_acc = train_correct / train_total_acc
                # train_acc = accuracy_score_cal(labels_numpy, predicted_numpy)
                time_elapsed = curr_time - start_time
                time_per_batch = time_elapsed / (batch_idx + 1)
                batches_left = len(train_loader) - batch_idx - 1
                time_left = batches_left * time_per_batch

                print(f"\rEpoch {epoch+1}/{num_epochs} - Batch {batch_idx+1}/{len(train_loader)} - "
                      f"Train Loss: {train_loss / train_total:.4f} - Train Acc: {train_acc:.4f} - train hamming loss: {train_hamming_loss:.4f} - "
                      f"Time elapsed: {time_elapsed:.0f}s - Time left: {time_left/60:.0f}min",
                      end='', flush=True)

                prev_time = curr_time

        train_loss /= train_total
        # Calculate accuracy score
        # train_acc = accuracy_score_cal(labels_numpy, predicted_numpy)
        train_acc = train_correct / train_total_acc

        model.eval()
        val_loss = 0.0
        val_correct = 0.0
        val_total = 0.0
        val_total_acc = 0.0
        val_predictions = []
        val_targets = []


        with torch.no_grad():
            for images, labels in val_loader:
                images = images.to(device)
                labels = labels.to(device)

                outputs = model(images)
                _, predicted = torch.max(outputs.data, 1)
                predicted = (outputs > 0.5).float()
                # predicted = F.one_hot(predicted, num_classes=NUM_CLASSES).float()
                #print(predicted)
                loss = criterion(outputs, labels)

                # Convert predicted and labels tensors to NumPy arrays
                predicted_numpy = predicted.cpu().numpy()
                labels_numpy = labels.cpu().numpy()

                val_loss += loss.item() * images.size(0)
                val_correct += accuracy_score_cal(labels_numpy, predicted_numpy)
                val_total += labels.size(0)
                val_total_acc += 64*9

                val_predictions.extend(predicted.tolist())
                val_targets.extend(labels.tolist())

                # Calculate additional evaluation metrics
                val_hamming_loss = hamming_loss(val_targets, val_predictions)
                val_f1 = f1_score(val_targets, val_predictions, average='micro')
                val_precision = precision_score(val_targets, val_predictions, average='micro')
                val_recall = recall_score(val_targets, val_predictions, average='micro')

        val_loss /= val_total
        # Calculate accuracy score
        # val_acc = accuracy_score(labels, predicted)
        val_acc = val_correct / val_total_acc

        time_elapsed = time.time() - start_time
        time_left = (num_epochs - epoch - 1) * time_elapsed

        print(f"\rEpoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f} - Train Acc: {train_acc:.4f} - "
          f"Train F1: {train_f1:.4f} - Train Precision: {train_precision:.4f} - Train Recall: {train_recall:.4f} - train hamming loss: {train_hamming_loss:.4f} -"
          f"Val Loss: {val_loss:.4f} - Val Acc: {val_acc:.4f} - "
          f"Val F1: {val_f1:.4f} - Val Precision: {val_precision:.4f} - Val Recall: {val_recall:.4f} - val hamming loss: {val_hamming_loss:.4f} -"
          f"Time elapsed: {time_elapsed:.0f}s - Time left: {time_left:.0f}s")

        # Append training and validation metrics to history dictionary
        history['epoch'].append(epoch + 1)
        history['train_hamming_loss'].append(train_hamming_loss)
        history['train_loss'].append(train_loss)
        history['train_acc'].append(train_acc)
        history['train_f1'].append(train_f1)
        history['train_precision'].append(train_precision)
        history['train_recall'].append(train_recall)
        history['val_loss'].append(val_loss)
        history['val_hamming_loss'].append(val_hamming_loss)
        history['val_acc'].append(val_acc)
        history['val_f1'].append(val_f1)
        history['val_precision'].append(val_precision)
        history['val_recall'].append(val_recall)

        if val_acc > best_val_acc:
            best_val_acc = val_acc
            torch.save(model.state_dict(), "best_model_vgg.pth")

    time_elapsed = time.time() - since
    print(f"Training complete in {time_elapsed:.0f}s")
    print(f"Best validation accuracy: {best_val_acc:.4f}")

    # Save history dictionary to a CSV file
    df = pd.DataFrame(history)
    df.to_csv(csv_file, index=False)

    # Plotting
    plt.figure(figsize=(12, 6))
    plt.subplot(1, 2, 1)
    plt.plot(history['epoch'], history['train_loss'], label='Train Loss')
    plt.plot(history['epoch'], history['val_loss'], label='Validation Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title('Training & Validation Loss')
    plt.legend()

    plt.subplot(1, 2, 2)
    plt.plot(history['epoch'], history['train_acc'], label='Train Accuracy')
    plt.plot(history['epoch'], history['val_acc'], label='Validation Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.title('Training & Validation Accuracy')
    plt.legend()

    plt.tight_layout()
    plt.show()

csv_file = 'training_history_vgg.csv'

print('start runnig ...')

train(model, train_loader, validation_loader, criterion, optimizer, DEVICE, 50, csv_file, history)

